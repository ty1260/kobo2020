{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment9_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCVWfz-3LZ_H",
        "colab_type": "text"
      },
      "source": [
        "### 第9回レポート課題その1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjY3-U9wkk0K",
        "colab_type": "text"
      },
      "source": [
        "今回の実行分は前回のコードの続きに書いたが, 誤って前回分を削除してしまったので今回の部分のみをのせる."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfLmqDVKChFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84f96e78-563c-4c66-d114-2cda3300f507"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 単層ニューラルネットワークを定義\n",
        "class SingleLayerNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_labels):\n",
        "        super(SingleLayerNN, self).__init__()\n",
        "        self.linear = nn.Linear(embedding_dim, num_labels) #todo linear層を追加\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h1 = self.linear(x) #todo xをlinear層に入力\n",
        "        return nn.Softmax(h1) #todo h1をsoftmaxしたものを返す\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x) #todo データサイズを返す\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out_x = self.x[idx] #todo idx番目のxの要素を返す\n",
        "        out_y = self.y[idx] #todo idx番目のyの要素を返す\n",
        "        return out_x, out_y\n",
        "        \n",
        "torch.manual_seed(1)\n",
        "\n",
        "embedding_dim = 300\n",
        "num_labels = 4\n",
        "NUM_EPOCH = 100\n",
        "\n",
        "train_x, train_y = torch.load(\"/content/drive/My Drive/data/train_x.pt\"), torch.load(\"/content/drive/My Drive/data/train_y.pt\")\n",
        "valid_x, valid_y = torch.load(\"/content/drive/My Drive/data/valid_x.pt\"), torch.load(\"/content/drive/My Drive/data/valid_y.pt\")\n",
        "\n",
        "# データとラベルを1つにまとめる\n",
        "dataset = MyDataset(train_x, train_y)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()#todo 損失関数としてCrossEntropyLossを用いる\n",
        "\n",
        "\n",
        "def train(model, train_loader):\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model.forward(data.type(torch.FloatTensor))  #todo dataをmodelに入力\n",
        "        loss = loss_fn(pred, target)  #todo predとtargetと損失関数からロスを計算\n",
        "        loss.backward() # 逆誤差伝搬を実施\n",
        "        optimizer.step() # パラメータを更新\n",
        "\n",
        "        \n",
        "def evaluation(model, data, target):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred =  model(data.type(torch.FloatTensor)) #todo dataをmodelに入力\n",
        "        loss = loss_fn(pred, target)  #todo predとtargetと損失関数からロスを計算\n",
        "        pred_labels = torch.argmax(pred, axis=1)  #todo 推定したラベルを代入\n",
        "        acc = (pred_labels == target).sum().item() / len(pred_labels) #todo pred_labelsとtargetから正解率を計算\n",
        "    return loss.item(), acc\n",
        "\n",
        "\n",
        "batch_size_list = [1, 2, 4, 8, 16, 32, 64, 128, 256] #todo バッチサイズの値のリスト．1,2,4,8,…が入る\n",
        "\n",
        "for batch_size in batch_size_list:\n",
        "    model = SingleLayerNN(embedding_dim, num_labels)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    # ミニバッチを扱うためのデータローダを作成\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(NUM_EPOCH):\n",
        "        start_time = time.time() # 学習開始時の時間を取得\n",
        "        train(model, train_loader)\n",
        "        took_time = time.time() - start_time #todo 学習にかかった時間を代入\n",
        "\n",
        "        valid_loss, valid_acc = evaluation(model, valid_x, valid_y)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"batch size:{batch_size}\\tepoch: {epoch}\")\n",
        "            print(f\"train time: {took_time}\")\n",
        "            print(f\"<valid>\\tloss: {valid_loss}\\tacc: {valid_acc}\")\n",
        "    \n",
        "    print(\"\\n================\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch size:1\tepoch: 0\n",
            "train time: 3.4327142238616943\n",
            "<valid>\tloss: 0.9587206244468689\tacc: 0.800599700149925\n",
            "batch size:1\tepoch: 10\n",
            "train time: 3.3923325538635254\n",
            "<valid>\tloss: 0.9397221803665161\tacc: 0.8013493253373314\n",
            "batch size:1\tepoch: 20\n",
            "train time: 3.4230799674987793\n",
            "<valid>\tloss: 0.9378631114959717\tacc: 0.8020989505247377\n",
            "batch size:1\tepoch: 30\n",
            "train time: 3.4563117027282715\n",
            "<valid>\tloss: 0.936996340751648\tacc: 0.8035982008995503\n",
            "batch size:1\tepoch: 40\n",
            "train time: 3.40429949760437\n",
            "<valid>\tloss: 0.9364750981330872\tacc: 0.802848575712144\n",
            "batch size:1\tepoch: 50\n",
            "train time: 3.429076671600342\n",
            "<valid>\tloss: 0.9360454082489014\tacc: 0.8020989505247377\n",
            "batch size:1\tepoch: 60\n",
            "train time: 3.393639326095581\n",
            "<valid>\tloss: 0.8930366635322571\tacc: 0.8538230884557722\n",
            "batch size:1\tepoch: 70\n",
            "train time: 3.289168357849121\n",
            "<valid>\tloss: 0.8867972493171692\tacc: 0.8590704647676162\n",
            "batch size:1\tepoch: 80\n",
            "train time: 3.3845012187957764\n",
            "<valid>\tloss: 0.885372519493103\tacc: 0.8598200899550225\n",
            "batch size:1\tepoch: 90\n",
            "train time: 3.3744046688079834\n",
            "<valid>\tloss: 0.8844170570373535\tacc: 0.8620689655172413\n",
            "\n",
            "================\n",
            "\n",
            "batch size:2\tepoch: 0\n",
            "train time: 1.84647798538208\n",
            "<valid>\tloss: 0.9724141359329224\tacc: 0.8020989505247377\n",
            "batch size:2\tepoch: 10\n",
            "train time: 1.767179250717163\n",
            "<valid>\tloss: 0.9423859119415283\tacc: 0.7998500749625187\n",
            "batch size:2\tepoch: 20\n",
            "train time: 1.7838430404663086\n",
            "<valid>\tloss: 0.9398484230041504\tacc: 0.800599700149925\n",
            "batch size:2\tepoch: 30\n",
            "train time: 1.8132224082946777\n",
            "<valid>\tloss: 0.9385116100311279\tacc: 0.8035982008995503\n",
            "batch size:2\tepoch: 40\n",
            "train time: 1.8376777172088623\n",
            "<valid>\tloss: 0.9378169178962708\tacc: 0.8043478260869565\n",
            "batch size:2\tepoch: 50\n",
            "train time: 1.7992968559265137\n",
            "<valid>\tloss: 0.9373283386230469\tacc: 0.8058470764617691\n",
            "batch size:2\tepoch: 60\n",
            "train time: 1.7739574909210205\n",
            "<valid>\tloss: 0.9369872212409973\tacc: 0.8058470764617691\n",
            "batch size:2\tepoch: 70\n",
            "train time: 1.755338430404663\n",
            "<valid>\tloss: 0.9366870522499084\tacc: 0.8050974512743628\n",
            "batch size:2\tepoch: 80\n",
            "train time: 1.7460906505584717\n",
            "<valid>\tloss: 0.9364578127861023\tacc: 0.8065967016491754\n",
            "batch size:2\tepoch: 90\n",
            "train time: 1.746995210647583\n",
            "<valid>\tloss: 0.9362329840660095\tacc: 0.8058470764617691\n",
            "\n",
            "================\n",
            "\n",
            "batch size:4\tepoch: 0\n",
            "train time: 0.9060168266296387\n",
            "<valid>\tloss: 0.9951785206794739\tacc: 0.7976011994002998\n",
            "batch size:4\tepoch: 10\n",
            "train time: 0.8771953582763672\n",
            "<valid>\tloss: 0.9468162059783936\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 20\n",
            "train time: 0.9125804901123047\n",
            "<valid>\tloss: 0.9426440596580505\tacc: 0.7983508245877061\n",
            "batch size:4\tepoch: 30\n",
            "train time: 0.893258810043335\n",
            "<valid>\tloss: 0.9408411979675293\tacc: 0.8013493253373314\n",
            "batch size:4\tepoch: 40\n",
            "train time: 0.8992624282836914\n",
            "<valid>\tloss: 0.9399241209030151\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 50\n",
            "train time: 0.8999133110046387\n",
            "<valid>\tloss: 0.9391137361526489\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 60\n",
            "train time: 0.9047155380249023\n",
            "<valid>\tloss: 0.9385632276535034\tacc: 0.8035982008995503\n",
            "batch size:4\tepoch: 70\n",
            "train time: 0.9022157192230225\n",
            "<valid>\tloss: 0.9381746649742126\tacc: 0.8043478260869565\n",
            "batch size:4\tepoch: 80\n",
            "train time: 0.9051768779754639\n",
            "<valid>\tloss: 0.9379227757453918\tacc: 0.8020989505247377\n",
            "batch size:4\tepoch: 90\n",
            "train time: 0.8807604312896729\n",
            "<valid>\tloss: 0.9375886917114258\tacc: 0.8050974512743628\n",
            "\n",
            "================\n",
            "\n",
            "batch size:8\tepoch: 0\n",
            "train time: 0.5004963874816895\n",
            "<valid>\tloss: 1.0347410440444946\tacc: 0.7938530734632684\n",
            "batch size:8\tepoch: 10\n",
            "train time: 0.4899773597717285\n",
            "<valid>\tloss: 0.9539514183998108\tacc: 0.800599700149925\n",
            "batch size:8\tepoch: 20\n",
            "train time: 0.481534481048584\n",
            "<valid>\tloss: 0.9472652673721313\tacc: 0.800599700149925\n",
            "batch size:8\tepoch: 30\n",
            "train time: 0.4730377197265625\n",
            "<valid>\tloss: 0.9444462060928345\tacc: 0.7998500749625187\n",
            "batch size:8\tepoch: 40\n",
            "train time: 0.4685249328613281\n",
            "<valid>\tloss: 0.9428423643112183\tacc: 0.7991004497751124\n",
            "batch size:8\tepoch: 50\n",
            "train time: 0.4801511764526367\n",
            "<valid>\tloss: 0.9417800307273865\tacc: 0.8020989505247377\n",
            "batch size:8\tepoch: 60\n",
            "train time: 0.4949989318847656\n",
            "<valid>\tloss: 0.9409576058387756\tacc: 0.8013493253373314\n",
            "batch size:8\tepoch: 70\n",
            "train time: 0.48453664779663086\n",
            "<valid>\tloss: 0.9403571486473083\tacc: 0.8020989505247377\n",
            "batch size:8\tepoch: 80\n",
            "train time: 0.47576284408569336\n",
            "<valid>\tloss: 0.9398748874664307\tacc: 0.8013493253373314\n",
            "batch size:8\tepoch: 90\n",
            "train time: 0.4719398021697998\n",
            "<valid>\tloss: 0.9394803047180176\tacc: 0.8013493253373314\n",
            "\n",
            "================\n",
            "\n",
            "batch size:16\tepoch: 0\n",
            "train time: 0.27730321884155273\n",
            "<valid>\tloss: 1.096767544746399\tacc: 0.7938530734632684\n",
            "batch size:16\tepoch: 10\n",
            "train time: 0.27251625061035156\n",
            "<valid>\tloss: 0.9651311039924622\tacc: 0.7998500749625187\n",
            "batch size:16\tepoch: 20\n",
            "train time: 0.275054931640625\n",
            "<valid>\tloss: 0.9545049071311951\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 30\n",
            "train time: 0.2691924571990967\n",
            "<valid>\tloss: 0.9499592185020447\tacc: 0.8013493253373314\n",
            "batch size:16\tepoch: 40\n",
            "train time: 0.28226208686828613\n",
            "<valid>\tloss: 0.9473902583122253\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 50\n",
            "train time: 0.28786396980285645\n",
            "<valid>\tloss: 0.9456802010536194\tacc: 0.7998500749625187\n",
            "batch size:16\tepoch: 60\n",
            "train time: 0.28084731101989746\n",
            "<valid>\tloss: 0.9444577097892761\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 70\n",
            "train time: 0.27704882621765137\n",
            "<valid>\tloss: 0.9435297846794128\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 80\n",
            "train time: 0.276120662689209\n",
            "<valid>\tloss: 0.9427953958511353\tacc: 0.7991004497751124\n",
            "batch size:16\tepoch: 90\n",
            "train time: 0.2651252746582031\n",
            "<valid>\tloss: 0.9421961307525635\tacc: 0.800599700149925\n",
            "\n",
            "================\n",
            "\n",
            "batch size:32\tepoch: 0\n",
            "train time: 0.162675142288208\n",
            "<valid>\tloss: 1.1795045137405396\tacc: 0.7901049475262368\n",
            "batch size:32\tepoch: 10\n",
            "train time: 0.16930794715881348\n",
            "<valid>\tloss: 0.9833818674087524\tacc: 0.7976011994002998\n",
            "batch size:32\tepoch: 20\n",
            "train time: 0.16820526123046875\n",
            "<valid>\tloss: 0.9660875201225281\tacc: 0.7998500749625187\n",
            "batch size:32\tepoch: 30\n",
            "train time: 0.16340875625610352\n",
            "<valid>\tloss: 0.9589011073112488\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 40\n",
            "train time: 0.16792035102844238\n",
            "<valid>\tloss: 0.954802393913269\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 50\n",
            "train time: 0.1677112579345703\n",
            "<valid>\tloss: 0.9520991444587708\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 60\n",
            "train time: 0.16145777702331543\n",
            "<valid>\tloss: 0.9501587152481079\tacc: 0.7998500749625187\n",
            "batch size:32\tepoch: 70\n",
            "train time: 0.17147040367126465\n",
            "<valid>\tloss: 0.9486894011497498\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 80\n",
            "train time: 0.1632401943206787\n",
            "<valid>\tloss: 0.9475265145301819\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 90\n",
            "train time: 0.16382718086242676\n",
            "<valid>\tloss: 0.946584165096283\tacc: 0.800599700149925\n",
            "\n",
            "================\n",
            "\n",
            "batch size:64\tepoch: 0\n",
            "train time: 0.11607837677001953\n",
            "<valid>\tloss: 1.252986192703247\tacc: 0.7721139430284858\n",
            "batch size:64\tepoch: 10\n",
            "train time: 0.11186718940734863\n",
            "<valid>\tloss: 1.013858675956726\tacc: 0.795352323838081\n",
            "batch size:64\tepoch: 20\n",
            "train time: 0.11319351196289062\n",
            "<valid>\tloss: 0.9849323034286499\tacc: 0.7983508245877061\n",
            "batch size:64\tepoch: 30\n",
            "train time: 0.12191534042358398\n",
            "<valid>\tloss: 0.9731804132461548\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 40\n",
            "train time: 0.11139917373657227\n",
            "<valid>\tloss: 0.9665709733963013\tacc: 0.7991004497751124\n",
            "batch size:64\tepoch: 50\n",
            "train time: 0.11164045333862305\n",
            "<valid>\tloss: 0.9622400999069214\tacc: 0.800599700149925\n",
            "batch size:64\tepoch: 60\n",
            "train time: 0.11977052688598633\n",
            "<valid>\tloss: 0.9591432213783264\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 70\n",
            "train time: 0.11381173133850098\n",
            "<valid>\tloss: 0.9568002223968506\tacc: 0.800599700149925\n",
            "batch size:64\tepoch: 80\n",
            "train time: 0.1149139404296875\n",
            "<valid>\tloss: 0.9549495577812195\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 90\n",
            "train time: 0.11267662048339844\n",
            "<valid>\tloss: 0.9534493684768677\tacc: 0.8013493253373314\n",
            "\n",
            "================\n",
            "\n",
            "batch size:128\tepoch: 0\n",
            "train time: 0.10262465476989746\n",
            "<valid>\tloss: 1.3098851442337036\tacc: 0.7796101949025487\n",
            "batch size:128\tepoch: 10\n",
            "train time: 0.0986166000366211\n",
            "<valid>\tloss: 1.0640039443969727\tacc: 0.7938530734632684\n",
            "batch size:128\tepoch: 20\n",
            "train time: 0.09158134460449219\n",
            "<valid>\tloss: 1.0162028074264526\tacc: 0.795352323838081\n",
            "batch size:128\tepoch: 30\n",
            "train time: 0.09086871147155762\n",
            "<valid>\tloss: 0.996565580368042\tacc: 0.7976011994002998\n",
            "batch size:128\tepoch: 40\n",
            "train time: 0.09058165550231934\n",
            "<valid>\tloss: 0.9856399893760681\tacc: 0.7983508245877061\n",
            "batch size:128\tepoch: 50\n",
            "train time: 0.09103751182556152\n",
            "<valid>\tloss: 0.9785651564598083\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 60\n",
            "train time: 0.09181523323059082\n",
            "<valid>\tloss: 0.9735413193702698\tacc: 0.7998500749625187\n",
            "batch size:128\tepoch: 70\n",
            "train time: 0.09323453903198242\n",
            "<valid>\tloss: 0.9697608947753906\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 80\n",
            "train time: 0.09246993064880371\n",
            "<valid>\tloss: 0.966791570186615\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 90\n",
            "train time: 0.09243178367614746\n",
            "<valid>\tloss: 0.9643874168395996\tacc: 0.7998500749625187\n",
            "\n",
            "================\n",
            "\n",
            "batch size:256\tepoch: 0\n",
            "train time: 0.07844233512878418\n",
            "<valid>\tloss: 1.3434481620788574\tacc: 0.676911544227886\n",
            "batch size:256\tepoch: 10\n",
            "train time: 0.08047938346862793\n",
            "<valid>\tloss: 1.1388838291168213\tacc: 0.7901049475262368\n",
            "batch size:256\tepoch: 20\n",
            "train time: 0.07925939559936523\n",
            "<valid>\tloss: 1.0688270330429077\tacc: 0.7916041979010495\n",
            "batch size:256\tepoch: 30\n",
            "train time: 0.08188986778259277\n",
            "<valid>\tloss: 1.036470890045166\tacc: 0.7923538230884558\n",
            "batch size:256\tepoch: 40\n",
            "train time: 0.07957983016967773\n",
            "<valid>\tloss: 1.0180315971374512\tacc: 0.7946026986506747\n",
            "batch size:256\tepoch: 50\n",
            "train time: 0.08253359794616699\n",
            "<valid>\tloss: 1.0060709714889526\tacc: 0.7961019490254873\n",
            "batch size:256\tepoch: 60\n",
            "train time: 0.07587099075317383\n",
            "<valid>\tloss: 0.9976276755332947\tacc: 0.7968515742128935\n",
            "batch size:256\tepoch: 70\n",
            "train time: 0.07837486267089844\n",
            "<valid>\tloss: 0.9913042783737183\tacc: 0.7968515742128935\n",
            "batch size:256\tepoch: 80\n",
            "train time: 0.07720732688903809\n",
            "<valid>\tloss: 0.9863716959953308\tacc: 0.7976011994002998\n",
            "batch size:256\tepoch: 90\n",
            "train time: 0.08588504791259766\n",
            "<valid>\tloss: 0.9824001789093018\tacc: 0.7976011994002998\n",
            "\n",
            "================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC2JCytEa5ot",
        "colab_type": "text"
      },
      "source": [
        "バッチサイズが大きくなるほど計算にかかる時間が短くなっていることが分かる."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTMi2rEBO94H",
        "colab_type": "text"
      },
      "source": [
        "#### 感想\n",
        "穴埋めはPytorchの復習にもなり, 前回よりもやりやすかった. ただ細かいエラーの対処に時間がかかったので今後の課題だと感じた."
      ]
    }
  ]
}