{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment9-1-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCVWfz-3LZ_H",
        "colab_type": "text"
      },
      "source": [
        "### 第9回レポート課題その1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7SXaaS9Em-U",
        "colab_type": "text"
      },
      "source": [
        "先のものに修正を加えました."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apsHR58Yg7Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "1496d6b0-1610-41cf-acd3-22581734f4e1"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.30 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.30)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.30->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.30->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR-djGuNAlrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a050ab7b-901d-49c9-b5b3-4c199c00245d"
      },
      "source": [
        "!wget http://130.153.158.5/~inaba/GoogleNews-vectors-negative300.bin"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-02 21:10:02--  http://130.153.158.5/~inaba/GoogleNews-vectors-negative300.bin\n",
            "Connecting to 130.153.158.5:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3644258522 (3.4G) [application/octet-stream]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   3.39G  29.3MB/s    in 1m 59s  \n",
            "\n",
            "2020-08-02 21:12:01 (29.2 MB/s) - ‘GoogleNews-vectors-negative300.bin’ saved [3644258522/3644258522]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8_TJz6zhCuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7ec0666d-8b1c-413f-bc39-3bab36dbf67d"
      },
      "source": [
        "!wget http://130.153.158.5/~inaba/data70.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-02 21:12:07--  http://130.153.158.5/~inaba/data70.zip\n",
            "Connecting to 130.153.158.5:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 392010 (383K) [application/zip]\n",
            "Saving to: ‘data70.zip’\n",
            "\n",
            "data70.zip          100%[===================>] 382.82K  1.30KB/s    in 6.4s    \n",
            "\n",
            "2020-08-02 21:12:13 (59.6 KB/s) - ‘data70.zip’ saved [392010/392010]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOxmcI-mhH0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "18a33bd2-a93e-4f7b-be6a-071555f10545"
      },
      "source": [
        "!unzip data70.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data70.zip\n",
            "  inflating: test.txt                \n",
            "  inflating: train.txt               \n",
            "  inflating: valid.txt               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edC5SFbQhoUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8688f6d8-a0b4-41d8-9974-7046ac6552c1"
      },
      "source": [
        "import gensim\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "w2v_path = './GoogleNews-vectors-negative300.bin' #todo GoogleNews-vectors-negative300.binのパスを指定\n",
        "data_path = './' #todo ファイル出力ディレクトリを指定\n",
        "data_path2 = '/content/drive/My Drive/data/'\n",
        "\n",
        "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(w2v_path, binary=True) #todo gensimでword2vecのモデルを読み込む\n",
        "\n",
        "category2num = {\"b\": 0, \"t\": 1, \"e\": 2, \"m\": 3}\n",
        "\n",
        "\n",
        "def get_feature(title):\n",
        "    word_list = title.split(' ')#todo タイトルをスペースで分割\n",
        "    vec_list = []\n",
        "    for word in word_list:\n",
        "        try:\n",
        "            vec = w2v_model[word]#todo wordを意味するベクトルを取得\n",
        "        except KeyError:\n",
        "            vec = np.zeros(300)#todo すべての要素が0のベクトルを代入\n",
        "        vec_list.append(vec)    \n",
        "    vec_np = np.array(vec_list) # numpyのarrayに変換\n",
        "    feature = np.sum(vec_np, axis=0)/len(vec_np)# 平均ベクトルを計算\n",
        "    return feature\n",
        "\n",
        "\n",
        "def get_data(fname):\n",
        "    label_list = []\n",
        "    feature_list = []\n",
        "    with open(fname, encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            if not line:\n",
        "                continue\n",
        "            data = line.split('\\t')\n",
        "            title = data[1]#todo dataからタイトルを取り出す\n",
        "            feature = get_feature(title) \n",
        "            feature_list.append(feature)\n",
        "            label = category2num[data[0]]\n",
        "            label_list.append(label)\n",
        "\n",
        "    features = torch.tensor(feature_list)#todo feature_listをtensorに変換\n",
        "    labels = torch.tensor(label_list)#todo label_listをtensorに変換\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "train_x, train_y = get_data(data_path + \"train.txt\")\n",
        "valid_x, valid_y = get_data(data_path + \"valid.txt\")\n",
        "test_x, test_y = get_data(data_path + \"test.txt\")\n",
        "\n",
        "# 保存\n",
        "torch.save(train_x, data_path2 + \"train_x.pt\")\n",
        "torch.save(train_y, data_path2 + \"train_y.pt\")\n",
        "torch.save(valid_x, data_path2 + \"valid_x.pt\")\n",
        "torch.save(valid_y, data_path2 + \"valid_y.pt\")\n",
        "torch.save(test_x, data_path2 + \"test_x.pt\")\n",
        "torch.save(test_y, data_path2 + \"test_y.pt\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfLmqDVKChFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ba77d2f-23b8-4ddd-a691-138af890388e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 単層ニューラルネットワークを定義\n",
        "class SingleLayerNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_labels):\n",
        "        super(SingleLayerNN, self).__init__()\n",
        "        self.linear = nn.Linear(embedding_dim, num_labels) #todo linear層を追加\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h1 = self.linear(x) #todo xをlinear層に入力\n",
        "        softmax = nn.Softmax()\n",
        "        return softmax(h1) #todo h1をsoftmaxしたものを返す\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x) #todo データサイズを返す\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out_x = self.x[idx] #todo idx番目のxの要素を返す\n",
        "        out_y = self.y[idx] #todo idx番目のyの要素を返す\n",
        "        return out_x, out_y\n",
        "        \n",
        "torch.manual_seed(1)\n",
        "\n",
        "embedding_dim = 300\n",
        "num_labels = 4\n",
        "NUM_EPOCH = 100\n",
        "\n",
        "train_x, train_y = torch.load(\"/content/drive/My Drive/data/train_x.pt\"), torch.load(\"/content/drive/My Drive/data/train_y.pt\")\n",
        "valid_x, valid_y = torch.load(\"/content/drive/My Drive/data/valid_x.pt\"), torch.load(\"/content/drive/My Drive/data/valid_y.pt\")\n",
        "\n",
        "# データとラベルを1つにまとめる\n",
        "dataset = MyDataset(train_x, train_y)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()#todo 損失関数としてCrossEntropyLossを用いる\n",
        "\n",
        "\n",
        "def train(model, train_loader):\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model.forward(data.type(torch.FloatTensor))  #todo dataをmodelに入力\n",
        "        loss = loss_fn(pred, target)  #todo predとtargetと損失関数からロスを計算\n",
        "        loss.backward() # 逆誤差伝搬を実施\n",
        "        optimizer.step() # パラメータを更新\n",
        "\n",
        "        \n",
        "def evaluation(model, data, target):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred =  model(data.type(torch.FloatTensor)) #todo dataをmodelに入力\n",
        "        loss = loss_fn(pred, target)  #todo predとtargetと損失関数からロスを計算\n",
        "        pred_labels = torch.argmax(pred, axis=1)  #todo 推定したラベルを代入\n",
        "        acc = (pred_labels == target).sum().item() / len(pred_labels) #todo pred_labelsとtargetから正解率を計算\n",
        "    return loss.item(), acc\n",
        "\n",
        "\n",
        "batch_size_list = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024] #todo バッチサイズの値のリスト．1,2,4,8,…が入る\n",
        "\n",
        "for batch_size in batch_size_list:\n",
        "    model = SingleLayerNN(embedding_dim, num_labels)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    # ミニバッチを扱うためのデータローダを作成\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(NUM_EPOCH):\n",
        "        start_time = time.time() # 学習開始時の時間を取得\n",
        "        train(model, train_loader)\n",
        "        took_time = time.time() - start_time #todo 学習にかかった時間を代入\n",
        "\n",
        "        valid_loss, valid_acc = evaluation(model, valid_x, valid_y)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"batch size:{batch_size}\\tepoch: {epoch}\")\n",
        "            print(f\"train time: {took_time}\")\n",
        "            print(f\"<valid>\\tloss: {valid_loss}\\tacc: {valid_acc}\")\n",
        "    \n",
        "    print(\"\\n================\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch size:1\tepoch: 0\n",
            "train time: 3.2745683193206787\n",
            "<valid>\tloss: 0.9587206244468689\tacc: 0.800599700149925\n",
            "batch size:1\tepoch: 10\n",
            "train time: 3.1874783039093018\n",
            "<valid>\tloss: 0.9397221803665161\tacc: 0.8013493253373314\n",
            "batch size:1\tepoch: 20\n",
            "train time: 3.032317638397217\n",
            "<valid>\tloss: 0.9378631114959717\tacc: 0.8020989505247377\n",
            "batch size:1\tepoch: 30\n",
            "train time: 3.1171605587005615\n",
            "<valid>\tloss: 0.936996340751648\tacc: 0.8035982008995503\n",
            "batch size:1\tepoch: 40\n",
            "train time: 3.2007553577423096\n",
            "<valid>\tloss: 0.9364750981330872\tacc: 0.802848575712144\n",
            "batch size:1\tepoch: 50\n",
            "train time: 3.1456024646759033\n",
            "<valid>\tloss: 0.9360454082489014\tacc: 0.8020989505247377\n",
            "batch size:1\tepoch: 60\n",
            "train time: 3.2307629585266113\n",
            "<valid>\tloss: 0.8930366635322571\tacc: 0.8538230884557722\n",
            "batch size:1\tepoch: 70\n",
            "train time: 3.5577666759490967\n",
            "<valid>\tloss: 0.8867972493171692\tacc: 0.8590704647676162\n",
            "batch size:1\tepoch: 80\n",
            "train time: 3.170229196548462\n",
            "<valid>\tloss: 0.885372519493103\tacc: 0.8598200899550225\n",
            "batch size:1\tepoch: 90\n",
            "train time: 3.1689298152923584\n",
            "<valid>\tloss: 0.8844170570373535\tacc: 0.8620689655172413\n",
            "\n",
            "================\n",
            "\n",
            "batch size:2\tepoch: 0\n",
            "train time: 1.6287312507629395\n",
            "<valid>\tloss: 0.9724141359329224\tacc: 0.8020989505247377\n",
            "batch size:2\tepoch: 10\n",
            "train time: 1.6460583209991455\n",
            "<valid>\tloss: 0.9423859119415283\tacc: 0.7998500749625187\n",
            "batch size:2\tepoch: 20\n",
            "train time: 1.7663893699645996\n",
            "<valid>\tloss: 0.9398484230041504\tacc: 0.800599700149925\n",
            "batch size:2\tepoch: 30\n",
            "train time: 1.6012651920318604\n",
            "<valid>\tloss: 0.9385116100311279\tacc: 0.8035982008995503\n",
            "batch size:2\tepoch: 40\n",
            "train time: 1.7541203498840332\n",
            "<valid>\tloss: 0.9378169178962708\tacc: 0.8043478260869565\n",
            "batch size:2\tepoch: 50\n",
            "train time: 1.618947982788086\n",
            "<valid>\tloss: 0.9373283386230469\tacc: 0.8058470764617691\n",
            "batch size:2\tepoch: 60\n",
            "train time: 1.596226453781128\n",
            "<valid>\tloss: 0.9369872212409973\tacc: 0.8058470764617691\n",
            "batch size:2\tepoch: 70\n",
            "train time: 1.7791063785552979\n",
            "<valid>\tloss: 0.9366870522499084\tacc: 0.8050974512743628\n",
            "batch size:2\tepoch: 80\n",
            "train time: 1.7743968963623047\n",
            "<valid>\tloss: 0.9364578127861023\tacc: 0.8065967016491754\n",
            "batch size:2\tepoch: 90\n",
            "train time: 1.5922002792358398\n",
            "<valid>\tloss: 0.9362329840660095\tacc: 0.8058470764617691\n",
            "\n",
            "================\n",
            "\n",
            "batch size:4\tepoch: 0\n",
            "train time: 0.8429625034332275\n",
            "<valid>\tloss: 0.9951785206794739\tacc: 0.7976011994002998\n",
            "batch size:4\tepoch: 10\n",
            "train time: 1.0350091457366943\n",
            "<valid>\tloss: 0.9468162059783936\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 20\n",
            "train time: 0.838397741317749\n",
            "<valid>\tloss: 0.9426440596580505\tacc: 0.7983508245877061\n",
            "batch size:4\tepoch: 30\n",
            "train time: 0.9419806003570557\n",
            "<valid>\tloss: 0.9408411979675293\tacc: 0.8013493253373314\n",
            "batch size:4\tepoch: 40\n",
            "train time: 0.8280529975891113\n",
            "<valid>\tloss: 0.9399241209030151\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 50\n",
            "train time: 0.8581440448760986\n",
            "<valid>\tloss: 0.9391137361526489\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 60\n",
            "train time: 0.8478240966796875\n",
            "<valid>\tloss: 0.9385632276535034\tacc: 0.8035982008995503\n",
            "batch size:4\tepoch: 70\n",
            "train time: 0.8479890823364258\n",
            "<valid>\tloss: 0.9381746649742126\tacc: 0.8043478260869565\n",
            "batch size:4\tepoch: 80\n",
            "train time: 0.845613956451416\n",
            "<valid>\tloss: 0.9379227757453918\tacc: 0.8020989505247377\n",
            "batch size:4\tepoch: 90\n",
            "train time: 0.8455557823181152\n",
            "<valid>\tloss: 0.9375886917114258\tacc: 0.8050974512743628\n",
            "\n",
            "================\n",
            "\n",
            "batch size:8\tepoch: 0\n",
            "train time: 0.44844532012939453\n",
            "<valid>\tloss: 1.0347410440444946\tacc: 0.7938530734632684\n",
            "batch size:8\tepoch: 10\n",
            "train time: 0.4564986228942871\n",
            "<valid>\tloss: 0.9539514183998108\tacc: 0.800599700149925\n",
            "batch size:8\tepoch: 20\n",
            "train time: 0.4534001350402832\n",
            "<valid>\tloss: 0.9472652673721313\tacc: 0.800599700149925\n",
            "batch size:8\tepoch: 30\n",
            "train time: 0.4612853527069092\n",
            "<valid>\tloss: 0.9444462060928345\tacc: 0.7998500749625187\n",
            "batch size:8\tepoch: 40\n",
            "train time: 0.4586796760559082\n",
            "<valid>\tloss: 0.9428423643112183\tacc: 0.7991004497751124\n",
            "batch size:8\tepoch: 50\n",
            "train time: 0.4472677707672119\n",
            "<valid>\tloss: 0.9417800307273865\tacc: 0.8020989505247377\n",
            "batch size:8\tepoch: 60\n",
            "train time: 0.44533514976501465\n",
            "<valid>\tloss: 0.9409576058387756\tacc: 0.8013493253373314\n",
            "batch size:8\tepoch: 70\n",
            "train time: 0.5114350318908691\n",
            "<valid>\tloss: 0.9403571486473083\tacc: 0.8020989505247377\n",
            "batch size:8\tepoch: 80\n",
            "train time: 0.44537830352783203\n",
            "<valid>\tloss: 0.9398748874664307\tacc: 0.8013493253373314\n",
            "batch size:8\tepoch: 90\n",
            "train time: 0.4701566696166992\n",
            "<valid>\tloss: 0.9394803047180176\tacc: 0.8013493253373314\n",
            "\n",
            "================\n",
            "\n",
            "batch size:16\tepoch: 0\n",
            "train time: 0.28165364265441895\n",
            "<valid>\tloss: 1.096767544746399\tacc: 0.7938530734632684\n",
            "batch size:16\tepoch: 10\n",
            "train time: 0.2550337314605713\n",
            "<valid>\tloss: 0.9651311039924622\tacc: 0.7998500749625187\n",
            "batch size:16\tepoch: 20\n",
            "train time: 0.25960874557495117\n",
            "<valid>\tloss: 0.9545049071311951\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 30\n",
            "train time: 0.25733423233032227\n",
            "<valid>\tloss: 0.9499592185020447\tacc: 0.8013493253373314\n",
            "batch size:16\tepoch: 40\n",
            "train time: 0.26067280769348145\n",
            "<valid>\tloss: 0.9473902583122253\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 50\n",
            "train time: 0.27219367027282715\n",
            "<valid>\tloss: 0.9456802010536194\tacc: 0.7998500749625187\n",
            "batch size:16\tepoch: 60\n",
            "train time: 0.25999879837036133\n",
            "<valid>\tloss: 0.9444577097892761\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 70\n",
            "train time: 0.25896382331848145\n",
            "<valid>\tloss: 0.9435297846794128\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 80\n",
            "train time: 0.27727246284484863\n",
            "<valid>\tloss: 0.9427953958511353\tacc: 0.7991004497751124\n",
            "batch size:16\tepoch: 90\n",
            "train time: 0.2709672451019287\n",
            "<valid>\tloss: 0.9421961307525635\tacc: 0.800599700149925\n",
            "\n",
            "================\n",
            "\n",
            "batch size:32\tepoch: 0\n",
            "train time: 0.16464567184448242\n",
            "<valid>\tloss: 1.1795045137405396\tacc: 0.7901049475262368\n",
            "batch size:32\tepoch: 10\n",
            "train time: 0.16294312477111816\n",
            "<valid>\tloss: 0.9833818674087524\tacc: 0.7976011994002998\n",
            "batch size:32\tepoch: 20\n",
            "train time: 0.1626145839691162\n",
            "<valid>\tloss: 0.9660875201225281\tacc: 0.7998500749625187\n",
            "batch size:32\tepoch: 30\n",
            "train time: 0.16858863830566406\n",
            "<valid>\tloss: 0.9589011073112488\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 40\n",
            "train time: 0.18021535873413086\n",
            "<valid>\tloss: 0.954802393913269\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 50\n",
            "train time: 0.19843268394470215\n",
            "<valid>\tloss: 0.9520991444587708\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 60\n",
            "train time: 0.15854144096374512\n",
            "<valid>\tloss: 0.9501587152481079\tacc: 0.7998500749625187\n",
            "batch size:32\tepoch: 70\n",
            "train time: 0.19223976135253906\n",
            "<valid>\tloss: 0.9486894011497498\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 80\n",
            "train time: 0.19442343711853027\n",
            "<valid>\tloss: 0.9475265145301819\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 90\n",
            "train time: 0.16283297538757324\n",
            "<valid>\tloss: 0.946584165096283\tacc: 0.800599700149925\n",
            "\n",
            "================\n",
            "\n",
            "batch size:64\tepoch: 0\n",
            "train time: 0.11177587509155273\n",
            "<valid>\tloss: 1.252986192703247\tacc: 0.7721139430284858\n",
            "batch size:64\tepoch: 10\n",
            "train time: 0.11406540870666504\n",
            "<valid>\tloss: 1.013858675956726\tacc: 0.795352323838081\n",
            "batch size:64\tepoch: 20\n",
            "train time: 0.11226940155029297\n",
            "<valid>\tloss: 0.9849323034286499\tacc: 0.7983508245877061\n",
            "batch size:64\tepoch: 30\n",
            "train time: 0.10906171798706055\n",
            "<valid>\tloss: 0.9731804132461548\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 40\n",
            "train time: 0.1152193546295166\n",
            "<valid>\tloss: 0.9665709733963013\tacc: 0.7991004497751124\n",
            "batch size:64\tepoch: 50\n",
            "train time: 0.10986614227294922\n",
            "<valid>\tloss: 0.9622400999069214\tacc: 0.800599700149925\n",
            "batch size:64\tepoch: 60\n",
            "train time: 0.1174154281616211\n",
            "<valid>\tloss: 0.9591432213783264\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 70\n",
            "train time: 0.11062312126159668\n",
            "<valid>\tloss: 0.9568002223968506\tacc: 0.800599700149925\n",
            "batch size:64\tepoch: 80\n",
            "train time: 0.11243391036987305\n",
            "<valid>\tloss: 0.9549495577812195\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 90\n",
            "train time: 0.13100624084472656\n",
            "<valid>\tloss: 0.9534493684768677\tacc: 0.8013493253373314\n",
            "\n",
            "================\n",
            "\n",
            "batch size:128\tepoch: 0\n",
            "train time: 0.09252548217773438\n",
            "<valid>\tloss: 1.3098851442337036\tacc: 0.7796101949025487\n",
            "batch size:128\tepoch: 10\n",
            "train time: 0.09330081939697266\n",
            "<valid>\tloss: 1.0640039443969727\tacc: 0.7938530734632684\n",
            "batch size:128\tepoch: 20\n",
            "train time: 0.09212183952331543\n",
            "<valid>\tloss: 1.0162028074264526\tacc: 0.795352323838081\n",
            "batch size:128\tepoch: 30\n",
            "train time: 0.09382104873657227\n",
            "<valid>\tloss: 0.996565580368042\tacc: 0.7976011994002998\n",
            "batch size:128\tepoch: 40\n",
            "train time: 0.09918355941772461\n",
            "<valid>\tloss: 0.9856399893760681\tacc: 0.7983508245877061\n",
            "batch size:128\tepoch: 50\n",
            "train time: 0.09485435485839844\n",
            "<valid>\tloss: 0.9785651564598083\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 60\n",
            "train time: 0.10502338409423828\n",
            "<valid>\tloss: 0.9735413193702698\tacc: 0.7998500749625187\n",
            "batch size:128\tepoch: 70\n",
            "train time: 0.0937345027923584\n",
            "<valid>\tloss: 0.9697608947753906\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 80\n",
            "train time: 0.09132122993469238\n",
            "<valid>\tloss: 0.966791570186615\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 90\n",
            "train time: 0.09119462966918945\n",
            "<valid>\tloss: 0.9643874168395996\tacc: 0.7998500749625187\n",
            "\n",
            "================\n",
            "\n",
            "batch size:256\tepoch: 0\n",
            "train time: 0.09442949295043945\n",
            "<valid>\tloss: 1.3434481620788574\tacc: 0.676911544227886\n",
            "batch size:256\tepoch: 10\n",
            "train time: 0.0778815746307373\n",
            "<valid>\tloss: 1.1388838291168213\tacc: 0.7901049475262368\n",
            "batch size:256\tepoch: 20\n",
            "train time: 0.07784128189086914\n",
            "<valid>\tloss: 1.0688270330429077\tacc: 0.7916041979010495\n",
            "batch size:256\tepoch: 30\n",
            "train time: 0.08144140243530273\n",
            "<valid>\tloss: 1.036470890045166\tacc: 0.7923538230884558\n",
            "batch size:256\tepoch: 40\n",
            "train time: 0.07652068138122559\n",
            "<valid>\tloss: 1.0180315971374512\tacc: 0.7946026986506747\n",
            "batch size:256\tepoch: 50\n",
            "train time: 0.08154964447021484\n",
            "<valid>\tloss: 1.0060709714889526\tacc: 0.7961019490254873\n",
            "batch size:256\tepoch: 60\n",
            "train time: 0.0800771713256836\n",
            "<valid>\tloss: 0.9976276755332947\tacc: 0.7968515742128935\n",
            "batch size:256\tepoch: 70\n",
            "train time: 0.0777583122253418\n",
            "<valid>\tloss: 0.9913042783737183\tacc: 0.7968515742128935\n",
            "batch size:256\tepoch: 80\n",
            "train time: 0.07833576202392578\n",
            "<valid>\tloss: 0.9863716959953308\tacc: 0.7976011994002998\n",
            "batch size:256\tepoch: 90\n",
            "train time: 0.07826948165893555\n",
            "<valid>\tloss: 0.9824001789093018\tacc: 0.7976011994002998\n",
            "\n",
            "================\n",
            "\n",
            "batch size:512\tepoch: 0\n",
            "train time: 0.06950139999389648\n",
            "<valid>\tloss: 1.3584065437316895\tacc: 0.4737631184407796\n",
            "batch size:512\tepoch: 10\n",
            "train time: 0.07052731513977051\n",
            "<valid>\tloss: 1.218245029449463\tacc: 0.7833583208395802\n",
            "batch size:512\tepoch: 20\n",
            "train time: 0.08254218101501465\n",
            "<valid>\tloss: 1.1433475017547607\tacc: 0.7916041979010495\n",
            "batch size:512\tepoch: 30\n",
            "train time: 0.06947183609008789\n",
            "<valid>\tloss: 1.098671555519104\tacc: 0.7923538230884558\n",
            "batch size:512\tepoch: 40\n",
            "train time: 0.06984663009643555\n",
            "<valid>\tloss: 1.0702648162841797\tacc: 0.7931034482758621\n",
            "batch size:512\tepoch: 50\n",
            "train time: 0.06999707221984863\n",
            "<valid>\tloss: 1.0509202480316162\tacc: 0.7931034482758621\n",
            "batch size:512\tepoch: 60\n",
            "train time: 0.06963086128234863\n",
            "<valid>\tloss: 1.0369625091552734\tacc: 0.7938530734632684\n",
            "batch size:512\tepoch: 70\n",
            "train time: 0.07106876373291016\n",
            "<valid>\tloss: 1.026411771774292\tacc: 0.795352323838081\n",
            "batch size:512\tepoch: 80\n",
            "train time: 0.06973695755004883\n",
            "<valid>\tloss: 1.0181546211242676\tacc: 0.795352323838081\n",
            "batch size:512\tepoch: 90\n",
            "train time: 0.07102251052856445\n",
            "<valid>\tloss: 1.0114991664886475\tacc: 0.795352323838081\n",
            "\n",
            "================\n",
            "\n",
            "batch size:1024\tepoch: 0\n",
            "train time: 0.06730198860168457\n",
            "<valid>\tloss: 1.3794910907745361\tacc: 0.41904047976011993\n",
            "batch size:1024\tepoch: 10\n",
            "train time: 0.06711626052856445\n",
            "<valid>\tloss: 1.285961627960205\tacc: 0.7511244377811095\n",
            "batch size:1024\tepoch: 20\n",
            "train time: 0.0777275562286377\n",
            "<valid>\tloss: 1.2233905792236328\tacc: 0.7886056971514243\n",
            "batch size:1024\tepoch: 30\n",
            "train time: 0.06483793258666992\n",
            "<valid>\tloss: 1.1778899431228638\tacc: 0.7916041979010495\n",
            "batch size:1024\tepoch: 40\n",
            "train time: 0.06534314155578613\n",
            "<valid>\tloss: 1.143635630607605\tacc: 0.7931034482758621\n",
            "batch size:1024\tepoch: 50\n",
            "train time: 0.06540441513061523\n",
            "<valid>\tloss: 1.1175342798233032\tacc: 0.7931034482758621\n",
            "batch size:1024\tepoch: 60\n",
            "train time: 0.07786059379577637\n",
            "<valid>\tloss: 1.0972718000411987\tacc: 0.7923538230884558\n",
            "batch size:1024\tepoch: 70\n",
            "train time: 0.06448793411254883\n",
            "<valid>\tloss: 1.08124577999115\tacc: 0.7931034482758621\n",
            "batch size:1024\tepoch: 80\n",
            "train time: 0.06990504264831543\n",
            "<valid>\tloss: 1.0683377981185913\tacc: 0.7931034482758621\n",
            "batch size:1024\tepoch: 90\n",
            "train time: 0.06595611572265625\n",
            "<valid>\tloss: 1.0577130317687988\tacc: 0.7931034482758621\n",
            "\n",
            "================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC2JCytEa5ot",
        "colab_type": "text"
      },
      "source": [
        "バッチサイズが大きくなるほど計算にかかる時間が短くなっていることが分かる."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTMi2rEBO94H",
        "colab_type": "text"
      },
      "source": [
        "#### 感想\n",
        "穴埋めはPytorchの復習にもなり, 前回よりもやりやすかった. ただ細かいエラーの対処に時間がかかったので今後の課題だと感じた."
      ]
    }
  ]
}